{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오늘의 목표          \n",
    "\n",
    "- Exploration 노드에 나온 openCV 활용방법 복습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp 3. 카메라 스티커앱 만들기 첫걸음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리 - 이미지를 불러와서 리사이징하기          \n",
    "\n",
    "> Q1. 이미지 하나를 불러와서 아래의 코드에 적용해 봅시다 :)...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "my_image_path = os.getenv('HOME')+'/aiffel/camera_sticker/images/image.jpg'\n",
    "img_bgr = cv2.imread(my_image_path)    #- OpenCV로 이미지를 읽어서\n",
    "img_bgr = cv2.resize(img_bgr, (640, 360))    # 640x360의 크기로 Resize\n",
    "img_show = img_bgr.copy()      #- 출력용 이미지 별도 보관\n",
    "plt.imshow(img_bgr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 채널 바꾸어 정상 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow 이전에 RGB 이미지로 바꾸는 것을 잊지마세요. \n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp 10. 인물사진 모드                  \n",
    "\n",
    "> Q2. 아래의 소스코드는 무엇을 하는 코드인가요? CV는 쬐금 나오지만.. 어..쨌든... 한번 되짚어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import os\n",
    "img_path = os.getenv('HOME')+'/aiffel/human_segmentation/images/my_image.png'  # 본인이 선택한 이미지의 경로에 맞게 바꿔 주세요. \n",
    "img_orig = cv2.imread(img_path) \n",
    "print (img_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabModel(object):\n",
    "    INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
    "    OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
    "    INPUT_SIZE = 513\n",
    "    FROZEN_GRAPH_NAME = 'frozen_inference_graph'\n",
    "\n",
    "    # __init__()에서 모델 구조를 직접 구현하는 대신, tar file에서 읽어들인 그래프구조 graph_def를 \n",
    "    # tf.compat.v1.import_graph_def를 통해 불러들여 활용하게 됩니다. \n",
    "    def __init__(self, tarball_path):\n",
    "        self.graph = tf.Graph()\n",
    "        graph_def = None\n",
    "        tar_file = tarfile.open(tarball_path)\n",
    "        for tar_info in tar_file.getmembers():\n",
    "            if self.FROZEN_GRAPH_NAME in os.path.basename(tar_info.name):\n",
    "                file_handle = tar_file.extractfile(tar_info)\n",
    "                graph_def = tf.compat.v1.GraphDef.FromString(file_handle.read())\n",
    "                break\n",
    "        tar_file.close()\n",
    "\n",
    "        with self.graph.as_default():\n",
    "    \t    tf.compat.v1.import_graph_def(graph_def, name='')\n",
    "\n",
    "        self.sess = tf.compat.v1.Session(graph=self.graph)\n",
    "\n",
    "    # 이미지를 전처리하여 Tensorflow 입력으로 사용 가능한 shape의 Numpy Array로 변환합니다.\n",
    "    def preprocess(self, img_orig):\n",
    "        height, width = img_orig.shape[:2]\n",
    "        resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n",
    "        target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
    "        resized_image = cv2.resize(img_orig, target_size)\n",
    "        resized_rgb = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "        img_input = resized_rgb\n",
    "        return img_input\n",
    "        \n",
    "    def run(self, image):\n",
    "        img_input = self.preprocess(image)\n",
    "\n",
    "        # Tensorflow V1에서는 model(input) 방식이 아니라 sess.run(feed_dict={input...}) 방식을 활용합니다.\n",
    "        batch_seg_map = self.sess.run(\n",
    "            self.OUTPUT_TENSOR_NAME,\n",
    "            feed_dict={self.INPUT_TENSOR_NAME: [img_input]})\n",
    "\n",
    "        seg_map = batch_seg_map[0]\n",
    "        return cv2.cvtColor(img_input, cv2.COLOR_RGB2BGR), seg_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#가중치 불러오는 내용인데 점점 cv랑 멀어지는 내용이지만..\n",
    "# define model and download & load pretrained weight\n",
    "_DOWNLOAD_URL_PREFIX = 'http://download.tensorflow.org/models/'\n",
    "\n",
    "model_dir = os.getenv('HOME')+'/aiffel/human_segmentation/models'\n",
    "tf.io.gfile.makedirs(model_dir)\n",
    "\n",
    "print ('temp directory:', model_dir)\n",
    "\n",
    "download_path = os.path.join(model_dir, 'deeplab_model.tar.gz')\n",
    "if not os.path.exists(download_path):\n",
    "    urllib.request.urlretrieve(_DOWNLOAD_URL_PREFIX + 'deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz',\n",
    "                   download_path)\n",
    "\n",
    "MODEL = DeepLabModel(download_path)\n",
    "print('model loaded successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지를 위의 네트워크에 통과시킵니다.\n",
    "img_resized, seg_map = MODEL.run(img_orig)\n",
    "print (img_orig.shape, img_resized.shape, seg_map.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#마스크 만들기...! 사람은 15번이래요.\n",
    "img_show = img_resized.copy()\n",
    "seg_map = np.where(seg_map == 15, 15, 0) # 예측 중 사람만 추출\n",
    "img_mask = seg_map * (255/seg_map.max()) # 255 normalization\n",
    "img_mask = img_mask.astype(np.uint8)\n",
    "color_mask = cv2.applyColorMap(img_mask, cv2.COLORMAP_JET)\n",
    "img_show = cv2.addWeighted(img_show, 0.6, color_mask, 0.35, 0.0)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_show, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 이 문법 기억하시죠?\n",
    "\n",
    "> Q3. 주석 달아 달라는 이야기입니다.... ㅋㅋㅋ 아래의 코드에서 각 옵션들이 어떤 의미었는지 기억하시리라 믿어요!\n",
    "> 각 함수들이 어떻게 작용하고 왜 필요한 것인지 개념을 정리해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배경 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask_color = cv2.cvtColor(img_mask_up, cv2.COLOR_GRAY2BGR)\n",
    "img_bg_mask = cv2.bitwise_not(img_mask_color)\n",
    "img_bg = cv2.bitwise_and(img_orig, img_bg_mask)\n",
    "plt.imshow(img_bg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배경 흐리게 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bg_blur = cv2.blur(img_bg, (13,13))\n",
    "plt.imshow(cv2.cvtColor(img_bg_blur, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배경과 사람 합성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_concat = np.where(img_mask_color==255, img_orig, img_bg_blur)\n",
    "plt.imshow(cv2.cvtColor(img_concat, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fund 20. 파이썬으로 이미지파일 다루기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pillow를 설명하더군요. 집어왔습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "#cv로 들어가기 전에, Pillow의 Image 함수로 만들어진 아래 코드를 한번 실습해봅시다.\n",
    "data = np.zeros([32, 32, 3], dtype=np.uint8)\n",
    "image = Image.fromarray(data, 'RGB')\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:, :] = [255, 0, 0]\n",
    "image = Image.fromarray(data, 'RGB')\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q4. 가로 세로 각 128 픽셀짜리 흰색 이미지를 만들어 화면에 표시해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q5. 연습용 이미지를 열어 width와 height를 출력하고, .save()를 이용하여 jpg 파일 포맷으로 저장해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 펀더멘탈에서 설명하는 openCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q6. 각 코드를 설명해주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "\n",
    "    # Take each frame\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    # define range of blue color in HSV\n",
    "    lower_blue = np.array([110,50,50])\n",
    "    upper_blue = np.array([130,255,255])\n",
    "\n",
    "    # Threshold the HSV image to get only blue colors\n",
    "    mask = cv.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv.bitwise_and(frame,frame, mask= mask)\n",
    "    cv.imshow('frame',frame)\n",
    "    cv.imshow('mask',mask)\n",
    "    cv.imshow('res',res)\n",
    "    k = cv.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV를 활용하여 비슷한 색깔 분포의 이미지 찾아내기              \n",
    "\n",
    "- 서로 다른 이미지 10장을 준비해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Q7. 아래 가이드 페이지를 참고하여 입력한 이미지의 색상별 히스토그램을 반환하는 함수를 작성해봅시다.\n",
    "> - [가이드페이지](https://docs.opencv.org/master/d1/db7/tutorial_py_histogram_begins.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
